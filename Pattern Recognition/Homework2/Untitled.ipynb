{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "#import dataset\n",
    "dataset = np.load('dataset.npy')\n",
    "\n",
    "#how many Gaussians are mixed\n",
    "gaussianAmt = 3\n",
    "\n",
    "#dimension of data in dataset\n",
    "dim = len(dataset[0])\n",
    "\n",
    "#treshold for checking numerical errors for randomization and singularity\n",
    "numericalErrorTreshold = 1e-6\n",
    "\n",
    "#addition factor for singular covariance matrix during the M-step\n",
    "#if the new covariance matrix becomes singular, factor*I will be added to it\n",
    "singularityAdditionFactor = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary libraries are imported. PDF of multivariate normal distribution is calculated with built-in function from scipy library. \n",
    "\n",
    "* gaussianAmt variable keeps how many Gaussian distributions are mixed in the dateset.\n",
    "* dim variable keeps the dimension of the dataset.\n",
    "* numericalErrorTreshold variable keeps the tolerable amount of numerical errors for randomization and singularity. Its use will be detailed in next parts.\n",
    "* singularityAdditionFactor variable keeps the amount of addition factor to the covariance matrix obtained in M-step of the algorithm. Its use is suggested in the link given below because the obtained new covariance matrix may become singular and it cannnot be used in PDF of multivariate normal distriburion. This tiny addition assures the algorithm may continue if ever a non-singular covariance matrix is obtained during the algorithm and I have witnessed its usefulness during my tests.\n",
    "\n",
    "Link: https://www.researchgate.net/post/How_to_fix_co_variance_matrix_going_singular_in_Gaussian_mixture_model_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean, covariance and mixing coefficient arrays\n",
    "means = []\n",
    "covariances = []\n",
    "coeffs = []\n",
    "\n",
    "#filling the arrays randomly\n",
    "for k in range(gaussianAmt):\n",
    "    means.append(np.random.uniform(-10, 10, dim))\n",
    "    #for covariance matrix, it needs to be positive semi-definite\n",
    "    posSemiDef = False\n",
    "    while posSemiDef == False:\n",
    "        A = np.random.uniform(-10, 10, (dim, dim))\n",
    "        #A^T * A is positive semi-definite\n",
    "        covariances.append(np.matmul(A.T, A))\n",
    "        #check if it is not positive semi-definite due to numerical error\n",
    "        #its eigenvalues must be all positive\n",
    "        posSemiDef = np.all(np.linalg.eigvalsh(covariances[k]) > numericalErrorTreshold)\n",
    "        if posSemiDef == False:\n",
    "            covariances.pop(k)\n",
    "            \n",
    "    coeffs.append(np.random.uniform(-10, 10))\n",
    "\n",
    "#calculating softmax of coeffs in order to make its sum = 1\n",
    "coeffs = np.exp(coeffs) / np.sum(np.exp(coeffs))\n",
    "\n",
    "#log likelihood value calculation\n",
    "logLikelihood = 0\n",
    "for n, data in enumerate(dataset):\n",
    "    sumWeightedProb = 0\n",
    "    for k in range(gaussianAmt):\n",
    "        weightedProb = coeffs[k]*multivariate_normal.pdf(data, means[k], covariances[k])\n",
    "        sumWeightedProb += weightedProb\n",
    "    logLikelihood += np.log(sumWeightedProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, random initial mean, covariance and mixture coefficients are calculated.\n",
    "\n",
    "* All values are randomized uniformly between -10 and 10.\n",
    "* Covariance matrix needs to be positive semi-definite. Because of that during its random initialization, one needs to be cautious. First of all, a matrix $A$ is randomized. Since $A^T \\times A$ is positive semi-definite, the random covariance matrix is chosen as such. A control is done for its positive semi-definiteness by checking if its all eigenvalues are positive.\n",
    "* The sum of mixture coefficients needs to be equal to 1. In order to ensure that, coeffients are randomized first and then its softmax is calculated. Sum of elements of an array after softmax process is equal to 1. Details of softmax can be seen in the link below:\n",
    "\n",
    "Link: https://en.wikipedia.org/wiki/Softmax_function\n",
    "\n",
    "* In the last step, initial log likelihood for mixture of multivariate normal distributions is calculated. Log likelihood value will be used for convergence control of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Log likelihood value difference: 553.4759472136986\n",
      "Iteration 2: Log likelihood value difference: 0.17537641866329068\n",
      "Iteration 3: Log likelihood value difference: 0.15718216197319634\n",
      "Iteration 4: Log likelihood value difference: 0.19082009761018526\n",
      "Iteration 5: Log likelihood value difference: 0.23011771130882153\n",
      "Iteration 6: Log likelihood value difference: 0.26703648089505805\n",
      "Iteration 7: Log likelihood value difference: 0.2928775634527483\n",
      "Iteration 8: Log likelihood value difference: 0.29919309640376923\n",
      "Iteration 9: Log likelihood value difference: 0.2832740453693532\n",
      "Iteration 10: Log likelihood value difference: 0.2511115651179807\n",
      "Iteration 11: Log likelihood value difference: 0.21396788389370158\n",
      "Iteration 12: Log likelihood value difference: 0.1819706349367607\n",
      "Iteration 13: Log likelihood value difference: 0.16031353730932096\n",
      "Iteration 14: Log likelihood value difference: 0.14964588202951745\n",
      "Iteration 15: Log likelihood value difference: 0.14945661936030774\n",
      "Iteration 16: Log likelihood value difference: 0.1647630975019183\n",
      "Iteration 17: Log likelihood value difference: 0.22059915214299508\n",
      "Iteration 18: Log likelihood value difference: 0.4440630947729005\n",
      "Iteration 19: Log likelihood value difference: 1.3721426172292013\n",
      "Iteration 20: Log likelihood value difference: 4.194619781448182\n",
      "Iteration 21: Log likelihood value difference: 7.344134186924748\n",
      "Iteration 22: Log likelihood value difference: 7.4011860811140195\n",
      "Iteration 23: Log likelihood value difference: 7.400108144939395\n",
      "Iteration 24: Log likelihood value difference: 10.67182628657065\n",
      "Iteration 25: Log likelihood value difference: 22.162415844291445\n",
      "Iteration 26: Log likelihood value difference: 13.139501834886687\n",
      "Iteration 27: Log likelihood value difference: 8.522800886127243\n",
      "Iteration 28: Log likelihood value difference: 10.60148983327531\n",
      "Iteration 29: Log likelihood value difference: 12.420086209774581\n",
      "Iteration 30: Log likelihood value difference: 12.374015176967987\n",
      "Iteration 31: Log likelihood value difference: 10.995711575782934\n",
      "Iteration 32: Log likelihood value difference: 8.19626332439725\n",
      "Iteration 33: Log likelihood value difference: 4.345962363609033\n",
      "Iteration 34: Log likelihood value difference: 2.420010223842155\n",
      "Iteration 35: Log likelihood value difference: 2.0071219690923954\n",
      "Iteration 36: Log likelihood value difference: 1.8361240562383045\n",
      "Iteration 37: Log likelihood value difference: 1.7627052460259165\n",
      "Iteration 38: Log likelihood value difference: 1.9129630334546164\n",
      "Iteration 39: Log likelihood value difference: 2.5199480747701273\n",
      "Iteration 40: Log likelihood value difference: 3.9889121072960734\n",
      "Iteration 41: Log likelihood value difference: 6.647555976235708\n",
      "Iteration 42: Log likelihood value difference: 9.440711570544408\n",
      "Iteration 43: Log likelihood value difference: 9.868050016847292\n",
      "Iteration 44: Log likelihood value difference: 5.374528103973489\n",
      "Iteration 45: Log likelihood value difference: 0.8909448599999905\n",
      "Iteration 46: Log likelihood value difference: 0.0370723752282629\n",
      "Iteration 47: Log likelihood value difference: 0.0008559731852528785\n",
      "Iteration 48: Log likelihood value difference: 1.882126480268198e-05\n",
      "Iteration 49: Log likelihood value difference: 4.136998086323729e-07\n"
     ]
    }
   ],
   "source": [
    "#treshold for stopping the algorithm\n",
    "convergenceTreshold = 1e-6\n",
    "stopAlgorithm = False\n",
    "#iteration counter\n",
    "nIter = 0\n",
    "\n",
    "while stopAlgorithm == False:\n",
    "    #E-step\n",
    "    mvGaussianProbWithCoeffs = []\n",
    "    condProbZ_nk = []\n",
    "    for n, data in enumerate(dataset):\n",
    "        mvGaussianProbWithCoeffs.append([])\n",
    "        condProbZ_nk.append([])\n",
    "        sumWeightedProb = 0\n",
    "        for k in range(gaussianAmt):\n",
    "            #probability of each data for each mixed Gaussian is calculated and weighted by corresponding mixture\n",
    "            #coefficient\n",
    "            weightedProb = coeffs[k]*multivariate_normal.pdf(data, means[k], covariances[k])\n",
    "            mvGaussianProbWithCoeffs[n].append(weightedProb)\n",
    "            #their sum is calculated\n",
    "            sumWeightedProb += weightedProb\n",
    "        for k in range(gaussianAmt):\n",
    "            #conditional probability of latent variable z is calculated\n",
    "            condProbZ_nk[n].append(mvGaussianProbWithCoeffs[n][k]/sumWeightedProb)\n",
    "    \n",
    "\n",
    "    #M-step\n",
    "    N_k = []\n",
    "    N = len(dataset)\n",
    "    meansNew = []\n",
    "    covariancesNew = []\n",
    "    coeffsNew = []\n",
    "\n",
    "    for k in range(gaussianAmt):\n",
    "        N_k.append(0)\n",
    "        meansNew.append(np.zeros(dim))\n",
    "        covariancesNew.append(np.zeros((dim, dim)))\n",
    "        coeffsNew.append(np.zeros(dim))\n",
    "        \n",
    "        #new means\n",
    "        for n, data in enumerate(dataset):\n",
    "            N_k[k] += condProbZ_nk[n][k]\n",
    "            meansNew[k] += condProbZ_nk[n][k]*data\n",
    "        meansNew[k] /= N_k[k]\n",
    "        \n",
    "        #new covariances\n",
    "        for n, data in enumerate(dataset):\n",
    "            covariancesNew[k] += condProbZ_nk[n][k]*np.matmul((data-meansNew[k]).reshape(dim,1), (data-meansNew[k]).reshape(dim,1).T)\n",
    "        covariancesNew[k] /= N_k[k]  \n",
    "        \n",
    "        #new coeffs\n",
    "        coeffsNew[k] = N_k[k]/N\n",
    "        \n",
    "        means[k] = meansNew[k]\n",
    "        covariances[k] = covariancesNew[k]\n",
    "        #if covariances are singular, i.e the determinant is zero then a tiny addition is done to its diagonal\n",
    "        #to make sure it is not singular so it can be used in PDF of multivariate normal distribution\n",
    "        if (np.linalg.det(covariances[k]) < numericalErrorTreshold):\n",
    "            covariances[k] += singularityAdditionFactor*np.eye(dim)\n",
    "        coeffs[k] = coeffsNew[k]\n",
    "    \n",
    "    #convergence check\n",
    "    logLikelihoodIter = 0\n",
    "    #new log likelihood is calculated\n",
    "    for n, data in enumerate(dataset):\n",
    "        sumWeightedProb = 0\n",
    "        for k in range(gaussianAmt):\n",
    "            weightedProb = coeffs[k]*multivariate_normal.pdf(data, means[k], covariances[k])\n",
    "            sumWeightedProb += weightedProb\n",
    "        logLikelihoodIter += np.log(sumWeightedProb)\n",
    "    \n",
    "    #if difference below the treshold, stop the algorithm\n",
    "    if abs(logLikelihoodIter - logLikelihood) < convergenceTreshold:\n",
    "        stopAlgorithm = True\n",
    "    \n",
    "    nIter += 1\n",
    "    \n",
    "    print('Iteration '+str(nIter)+': Log likelihood value difference: '+str(abs(logLikelihoodIter - logLikelihood)))\n",
    "    \n",
    "    logLikelihood = logLikelihoodIter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, algorithm is implemented.\n",
    "\n",
    "* Firstly, convergence treshold is decided. The algorithm works until convergence is obtained.\n",
    "* The algorithm starts with E-step. In this step, conditional probability of latent variable z is calculated. First of all, probabilities of each data for each mixed Gaussian is calculated and weighted with the corresponding mixture coefficient. Their values are stored in mvGaussianProbWithCoeffs array and sum of probabilities of each data is kept in  variable sumWeightedProb of every Gaussian. Then, the conditional probability of z is calculated by division of probability of each data being in a Gaussian and sum of all probabilities of all the Gaussians of that data.\n",
    "* Next step is N-step. In this step, new means, covariances and mixture coefficients are calculated. Firstly, new means are calculated by weighted average of data in dataset with corresponding conditional probability of corresponding latent value z. Then new covariances are calculated. New covariances of data are calculated by using the new means. After calculating the new covariances, the matrix may become singular which is not useful for probability calculation with PDF of multivariate normal distribution. In order to make it useful for the calculation, a very tiny factor is added to its diagonal so the algorithm may continue and it converges. There are other methods for circumventing the singularity problem such as re-initializing the covariance matrix etc. However, this little addition method is also accepted by literature and used in practice. The link is given in the initialization of the little factor. Finally, the new mixture coefficients are calculated by taking the average of conditional probabilities of latent variable z for each mixture.\n",
    "* The arrays are updated by the new ones.\n",
    "* For convergence, log likelihood is re-calculated with the new updated values. If the difference between log likelihood of previous step and current step is below the treshold, the algorithm stops.\n",
    "* In order to see the process and iteration count of the algorithm, iteration count and log likelihood differences are printed. In this example, the algorithm converges in 49 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final means: \n",
      "1: [0.70208114 0.66135866]\n",
      "2: [9.60515914 9.16835945]\n",
      "3: [4.3790422  4.35183625]\n",
      "\n",
      "Final covariances: \n",
      "1: [[ 2.11797449 -0.09973663]\n",
      " [-0.09973663  0.64083105]]\n",
      "2: [[ 2.01245136 -0.64166751]\n",
      " [-0.64166751  0.82171149]]\n",
      "3: [[ 2.74790459 -0.11922352]\n",
      " [-0.11922352  0.6180689 ]]\n",
      "\n",
      "Final coefficients: \n",
      "1: 0.333164749246527\n",
      "2: 0.3333333160484921\n",
      "3: 0.33350193470498074\n"
     ]
    }
   ],
   "source": [
    "print(\"Final means: \")\n",
    "for k in range(gaussianAmt):\n",
    "    print(str(k+1)+': '+str(means[k]))\n",
    "    \n",
    "print(\"\\nFinal covariances: \")\n",
    "for k in range(gaussianAmt):\n",
    "    print(str(k+1)+': '+str(covariances[k]))\n",
    "    \n",
    "print(\"\\nFinal coefficients: \")\n",
    "for k in range(gaussianAmt):\n",
    "    print(str(k+1)+': '+str(coeffs[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated values can be seen above for this example. However, these values may alter due to random initialization of the means, covariances and mixture coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#decide clusters for data accoring to conditional probability of latent variable z for each data\n",
    "clusters = []\n",
    "for k in range(gaussianAmt):\n",
    "    clusters.append([])\n",
    "\n",
    "for n, data in enumerate(dataset):\n",
    "    prob = 0\n",
    "    cluster = 0\n",
    "    for k in range(gaussianAmt):\n",
    "        probCluster = coeffs[k]*multivariate_normal.pdf(data, means[k], covariances[k])\n",
    "        if probCluster > prob:\n",
    "            prob = probCluster\n",
    "            cluster = k\n",
    "    clusters[cluster].append(n)\n",
    "    \n",
    "colors = ['red', 'blue', 'green', 'gray', 'yellow', 'cyan', 'magenta']\n",
    "\n",
    "#plot data according to their clusters decided\n",
    "for k in range(gaussianAmt):\n",
    "    for n in clusters[k]:\n",
    "        plt.scatter(dataset[n][0], dataset[n][1], c=colors[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above the data is clustered and plotted in different colors regarding the clusters. Clustering is done by comparing the conditional probability of latent value z of each data. According to the plot above, it seems that EM algorithm provides an accurate assumption for parameters and mixture coefficients of mixture of distributions for the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
